{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rizkyprofs/ML_DL/blob/main/ML_Week5_Task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JdbuJuG0NEt"
      },
      "source": [
        "# Analisis Data dan Visualisasi - Prediksi Penjualan Walmart\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDMrbMeb0NEy"
      },
      "source": [
        "## 1. Pendahuluan <a name=\"1\"></a>\n",
        "\n",
        "Pada notebook ini, kita akan melakukan analisis data dan visualisasi untuk dataset penjualan Walmart. Tujuan utama dari analisis ini adalah:\n",
        "\n",
        "1. Memahami struktur dan karakteristik data\n",
        "2. Mengidentifikasi pola dan tren dalam data\n",
        "3. Menganalisis hubungan antar variabel\n",
        "4. Menyajikan insight melalui visualisasi data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOTo1aBf0NEz"
      },
      "source": [
        "## 2. Import Library <a name=\"2\"></a>\n",
        "\n",
        "Library yang akan digunakan dalam analisis ini:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXtHYmEr0NE0",
        "outputId": "ed3ba3a9-e177-4acb-a81a-c9495f3825a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "harlfoxem_housesalesprediction_path = kagglehub.dataset_download('harlfoxem/housesalesprediction')\n",
        "nomanvb_tv_sales_forecast_path = kagglehub.dataset_download('nomanvb/tv-sales-forecast')\n",
        "\n",
        "# organizations_tevecsystems_retail_sales_forecasting_path = kagglehub.dataset_download('organizations/tevecsystems/retail-sales-forecasting')\n",
        "# Instead, try finding the correct username/dataset-name from Kaggle.\n",
        "# As an example, let's assume the correct handle is 'tevecsystems/retail-sales-forecasting':\n",
        "organizations_tevecsystems_retail_sales_forecasting_path = kagglehub.dataset_download('tevecsystems/retail-sales-forecasting')\n",
        "felixzhao_productdemandforecasting_path = kagglehub.dataset_download('felixzhao/productdemandforecasting')\n",
        "iamprateek_wallmart_sales_forecast_datasets_path = kagglehub.dataset_download('iamprateek/wallmart-sales-forecast-datasets')\n",
        "devashish0507_big_mart_sales_prediction_path = kagglehub.dataset_download('devashish0507/big-mart-sales-prediction')\n",
        "divyajeetthakur_walmart_sales_prediction_path = kagglehub.dataset_download('divyajeetthakur/walmart-sales-prediction')\n",
        "rutuspatel_walmart_dataset_retail_path = kagglehub.dataset_download('rutuspatel/walmart-dataset-retail')\n",
        "yasserh_walmart_dataset_path = kagglehub.dataset_download('yasserh/walmart-dataset')\n",
        "aslanahmedov_walmart_sales_forecast_path = kagglehub.dataset_download('aslanahmedov/walmart-sales-forecast')\n",
        "\n",
        "print('Data source import complete.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbGD-g1I0NE2"
      },
      "source": [
        "## 3. Load Dataset <a name=\"3\"></a>\n",
        "\n",
        "Mengambil dataset dari Kaggle dan memuatnya ke dalam DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "3qznH1tT0NE2",
        "outputId": "be2a4bff-b513-41bb-f37b-e74afe3dd6ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/cli.py\", line 68, in main\n",
            "    out = args.func(**command_args)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1734, in dataset_download_cli\n",
            "    with self.build_kaggle_client() as kaggle:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n",
            "    username=self.config_values['username'],\n",
            "             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'username'\n",
            "unzip:  cannot find or open wallmart-sales-forecast-datasets.zip, wallmart-sales-forecast-datasets.zip.zip or wallmart-sales-forecast-datasets.zip.ZIP.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "[Errno 21] Is a directory: '/kaggle/input/wallmart-sales-forecast-datasets'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c2f095701ea4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miamprateek_wallmart_sales_forecast_datasets_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/kaggle/input/wallmart-sales-forecast-datasets'"
          ]
        }
      ],
      "source": [
        "# Kode untuk download dataset dari Kaggle\n",
        "!kaggle datasets download -d iamprateek/wallmart-sales-forecast-datasets\n",
        "\n",
        "# Unzip file\n",
        "!unzip wallmart-sales-forecast-datasets.zip\n",
        "\n",
        "# Load dataset\n",
        "import pandas as pd\n",
        "df = pd.read_csv(iamprateek_wallmart_sales_forecast_datasets_path + '/Walmart_Store_sales.csv')\n",
        "\n",
        "\n",
        "# Menampilkan 5 baris pertama\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBFf6gih0NE3"
      },
      "source": [
        "## 4. Exploratory Data Analysis (EDA) <a name=\"4\"></a>\n",
        "\n",
        "### 4.1 Analisis Statistik Deskriptif <a name=\"4.1\"></a>\n",
        "\n",
        "Menganalisis statistik deskriptif untuk memahami distribusi data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWVOjk-f0NE4"
      },
      "outputs": [],
      "source": [
        "# Statistik deskriptif untuk variabel numerik\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXjuxXYe0NE5"
      },
      "source": [
        "### 4.2 Analisis Missing Values <a name=\"4.2\"></a>\n",
        "\n",
        "Memeriksa keberadaan missing values dalam dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8myA10lh0NE5"
      },
      "outputs": [],
      "source": [
        "# Menghitung jumlah missing values per kolom\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXRIl3ZD0NE6"
      },
      "source": [
        "### 4.3 Analisis Distribusi Data <a name=\"4.3\"></a>\n",
        "\n",
        "Menganalisis distribusi data untuk variabel-variabel penting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKl3jgPt0NE7"
      },
      "outputs": [],
      "source": [
        "# Analisis distribusi Weekly_Sales\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(data=df, x='Weekly_Sales', kde=True)\n",
        "plt.title('Distribusi Weekly Sales')\n",
        "plt.xlabel('Weekly Sales')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7jxEwpp0NE8"
      },
      "source": [
        "## 5. Visualisasi Data <a name=\"5\"></a>\n",
        "\n",
        "### 5.1 Visualisasi Univariate <a name=\"5.1\"></a>\n",
        "\n",
        "Analisis distribusi untuk setiap variabel secara terpisah:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lvl1oq0H0NE8"
      },
      "outputs": [],
      "source": [
        "# Visualisasi distribusi untuk variabel numerik\n",
        "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "for col in numeric_cols:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(data=df, x=col, kde=True)\n",
        "    plt.title(f'Distribusi {col}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OSd8aKw0NE8"
      },
      "source": [
        "### 5.2 Visualisasi Bivariate <a name=\"5.2\"></a>\n",
        "\n",
        "Analisis hubungan antara dua variabel:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ccGLwVQ0NE9"
      },
      "outputs": [],
      "source": [
        "# Scatter plot untuk melihat hubungan antar variabel\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.scatterplot(data=df, x='Temperature', y='Weekly_Sales')\n",
        "plt.title('Hubungan antara Temperature dan Weekly Sales')\n",
        "plt.xlabel('Temperature')\n",
        "plt.ylabel('Weekly Sales')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDj130bK0NE-"
      },
      "source": [
        "### 5.3 Visualisasi Multivariate <a name=\"5.3\"></a>\n",
        "\n",
        "Analisis hubungan antara multiple variabel:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1FyrQe_0NE-"
      },
      "outputs": [],
      "source": [
        "# Heatmap korelasi\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title('Heatmap Korelasi antar Variabel')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUNGLVKf0NE-"
      },
      "source": [
        "## 6. Kesimpulan <a name=\"6\"></a>\n",
        "\n",
        "Berdasarkan analisis yang telah dilakukan, kita dapat menyimpulkan:\n",
        "\n",
        "1. **Karakteristik Data**:\n",
        "   -\n",
        "\n",
        "2. **Pola dan Tren**:\n",
        "   -  \n",
        "\n",
        "3. **Hubungan antar Variabel**:\n",
        "   -\n",
        "\n",
        "4. **Insight Penting**:\n",
        "   -"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}